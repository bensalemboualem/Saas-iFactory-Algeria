<!DOCTYPE html>
<html lang="fr" dir="ltr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Format de R√©ponse API - IAFactory Algeria</title>
    <link rel="stylesheet" href="../../assets/css/docs-theme.css">
    <link rel="icon" href="../../assets/images/favicon.ico">
</head>
<body>
    <header class="docs-header">
        <div class="docs-logo">
            <img src="../../assets/images/logo.png" alt="IAFactory Algeria">
            <span>IAFactory Algeria</span>
        </div>
        
        <nav class="main-nav">
            <a href="../index.html">Documentation</a>
            <a href="https://app.iafactory-algeria.com">App</a>
            <a href="./index.html" class="active">API</a>
            <a href="https://jobs.iafactory-algeria.com">Jobs</a>
        </nav>
        
        <div class="docs-controls">
            <div class="language-switcher">
                <button data-lang="fr" class="active">üá´üá∑ FR</button>
                <button data-lang="en">üá¨üáß EN</button>
                <button data-lang="ar">üá∏üá¶ AR</button>
            </div>
            
            <div class="theme-toggle">
                <div class="theme-toggle-slider">‚òÄÔ∏è</div>
            </div>
        </div>
    </header>

    <div class="docs-container">
        <aside class="docs-sidebar">
            <div class="search-box">
                <span class="search-icon">üîç</span>
                <input type="text" placeholder="Rechercher...">
            </div>

            <div class="sidebar-section">
                <h3 class="sidebar-section-title">üîå API</h3>
                <ul class="sidebar-menu">
                    <li><a href="./quick-start.html">D√©marrage rapide</a></li>
                    <li><a href="./response-format.html" class="active">Format de r√©ponse</a></li>
                    <li><a href="./models-pricing.html">Mod√®les et tarifs</a></li>
                    <li><a href="./error-codes.html">Codes d'erreur</a></li>
                    <li><a href="./parameters.html">Param√®tres</a></li>
                    <li><a href="./optimization.html">Conseils d'optimisation</a></li>
                    <li><a href="./migration-openai.html">Migration depuis OpenAI</a></li>
                    <li><a href="./webhooks.html">Webhooks</a></li>
                </ul>
            </div>
        </aside>

        <main class="docs-main">
            <h1>üìã Format de R√©ponse API</h1>
            
            <p class="lead">Comprendre la structure des r√©ponses de l'API IAFactory Algeria.</p>

            <h2 id="reponse-standard">R√©ponse Standard (Non-Streaming)</h2>
            
            <p>Lorsque vous faites une requ√™te API sans streaming, vous recevez une r√©ponse JSON compl√®te :</p>

            <pre><code class="language-json">{
  "id": "chatcmpl-9x7k2j4mN8pQrStUvWxYz",
  "object": "chat.completion",
  "created": 1704283200,
  "model": "gpt-4.1",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Voici ma r√©ponse compl√®te √† votre question..."
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 42,
    "completion_tokens": 158,
    "total_tokens": 200
  },
  "system_fingerprint": "fp_iafactory_v1"
}</code></pre>

            <h3 id="champs-principaux">Champs Principaux</h3>

            <table>
                <thead>
                    <tr>
                        <th>Champ</th>
                        <th>Type</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>id</code></td>
                        <td>string</td>
                        <td>Identifiant unique de la compl√©tion</td>
                    </tr>
                    <tr>
                        <td><code>object</code></td>
                        <td>string</td>
                        <td>Type d'objet (toujours "chat.completion")</td>
                    </tr>
                    <tr>
                        <td><code>created</code></td>
                        <td>integer</td>
                        <td>Timestamp Unix de cr√©ation</td>
                    </tr>
                    <tr>
                        <td><code>model</code></td>
                        <td>string</td>
                        <td>Mod√®le utilis√© pour g√©n√©rer la r√©ponse</td>
                    </tr>
                    <tr>
                        <td><code>choices</code></td>
                        <td>array</td>
                        <td>Liste des r√©ponses g√©n√©r√©es (normalement 1 seul)</td>
                    </tr>
                    <tr>
                        <td><code>usage</code></td>
                        <td>object</td>
                        <td>Statistiques d'utilisation des tokens</td>
                    </tr>
                </tbody>
            </table>

            <h3 id="objet-choice">Objet Choice</h3>

            <p>Chaque √©l√©ment du tableau <code>choices</code> contient :</p>

            <table>
                <thead>
                    <tr>
                        <th>Champ</th>
                        <th>Type</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>index</code></td>
                        <td>integer</td>
                        <td>Index du choix (0 par d√©faut)</td>
                    </tr>
                    <tr>
                        <td><code>message</code></td>
                        <td>object</td>
                        <td>Message g√©n√©r√© par l'IA</td>
                    </tr>
                    <tr>
                        <td><code>finish_reason</code></td>
                        <td>string</td>
                        <td>Raison de l'arr√™t de g√©n√©ration</td>
                    </tr>
                    <tr>
                        <td><code>logprobs</code></td>
                        <td>object | null</td>
                        <td>Probabilit√©s logarithmiques (si demand√©es)</td>
                    </tr>
                </tbody>
            </table>

            <h3 id="finish-reason">Valeurs finish_reason</h3>

            <table>
                <thead>
                    <tr>
                        <th>Valeur</th>
                        <th>Signification</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>stop</code></td>
                        <td>R√©ponse compl√®te termin√©e naturellement</td>
                    </tr>
                    <tr>
                        <td><code>length</code></td>
                        <td>Arr√™t d√ª √† la limite de tokens (max_tokens atteint)</td>
                    </tr>
                    <tr>
                        <td><code>content_filter</code></td>
                        <td>R√©ponse bloqu√©e par le filtre de contenu</td>
                    </tr>
                    <tr>
                        <td><code>tool_calls</code></td>
                        <td>Mod√®le demande l'ex√©cution d'un outil (function calling)</td>
                    </tr>
                    <tr>
                        <td><code>null</code></td>
                        <td>G√©n√©ration toujours en cours (mode streaming)</td>
                    </tr>
                </tbody>
            </table>

            <h3 id="objet-usage">Objet Usage</h3>

            <p>Indique la consommation de tokens pour facturation :</p>

            <table>
                <thead>
                    <tr>
                        <th>Champ</th>
                        <th>Type</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>prompt_tokens</code></td>
                        <td>integer</td>
                        <td>Nombre de tokens dans votre prompt</td>
                    </tr>
                    <tr>
                        <td><code>completion_tokens</code></td>
                        <td>integer</td>
                        <td>Nombre de tokens dans la r√©ponse g√©n√©r√©e</td>
                    </tr>
                    <tr>
                        <td><code>total_tokens</code></td>
                        <td>integer</td>
                        <td>Total (prompt_tokens + completion_tokens)</td>
                    </tr>
                </tbody>
            </table>

            <h2 id="reponse-streaming">R√©ponse Streaming</h2>
            
            <p>Avec <code>stream: true</code>, vous recevez des √©v√©nements SSE (Server-Sent Events) :</p>

            <pre><code class="language-json">data: {"id":"chatcmpl-abc","object":"chat.completion.chunk","created":1704283200,"model":"gpt-4.1","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"chatcmpl-abc","object":"chat.completion.chunk","created":1704283200,"model":"gpt-4.1","choices":[{"index":0,"delta":{"content":"Voici"},"finish_reason":null}]}

data: {"id":"chatcmpl-abc","object":"chat.completion.chunk","created":1704283200,"model":"gpt-4.1","choices":[{"index":0,"delta":{"content":" ma"},"finish_reason":null}]}

data: {"id":"chatcmpl-abc","object":"chat.completion.chunk","created":1704283200,"model":"gpt-4.1","choices":[{"index":0,"delta":{"content":" r√©ponse"},"finish_reason":null}]}

data: {"id":"chatcmpl-abc","object":"chat.completion.chunk","created":1704283200,"model":"gpt-4.1","choices":[{"index":0,"delta":{},"finish_reason":"stop"}]}

data: [DONE]</code></pre>

            <p>Chaque chunk contient un fragment de la r√©ponse dans <code>delta.content</code>.</p>

            <h3 id="exemple-streaming">Exemple Python avec Streaming</h3>

            <pre><code class="language-python">import openai

openai.api_base = "https://api.iafactory-algeria.com/v1"
openai.api_key = "VOTRE_CLE_API"

response = openai.ChatCompletion.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": "Raconte une histoire"}],
    stream=True
)

full_response = ""
for chunk in response:
    if chunk.choices[0].delta.get("content"):
        content = chunk.choices[0].delta.content
        full_response += content
        print(content, end="", flush=True)

print("\n\nR√©ponse compl√®te:", full_response)</code></pre>

            <h2 id="gestion-erreurs">Format des Erreurs</h2>
            
            <p>En cas d'erreur, l'API retourne un JSON avec code HTTP appropri√© :</p>

            <pre><code class="language-json">{
  "error": {
    "message": "Invalid API key provided",
    "type": "invalid_request_error",
    "param": null,
    "code": "invalid_api_key"
  }
}</code></pre>

            <p><a href="./error-codes.html">Voir tous les codes d'erreur ‚Üí</a></p>

            <h2 id="function-calling">Function Calling (Appels de Fonctions)</h2>
            
            <p>Si vous utilisez des outils, la r√©ponse peut contenir <code>tool_calls</code> :</p>

            <pre><code class="language-json">{
  "id": "chatcmpl-xyz",
  "choices": [
    {
      "message": {
        "role": "assistant",
        "content": null,
        "tool_calls": [
          {
            "id": "call_abc123",
            "type": "function",
            "function": {
              "name": "get_weather",
              "arguments": "{\"location\": \"Alger\", \"unit\": \"celsius\"}"
            }
          }
        ]
      },
      "finish_reason": "tool_calls"
    }
  ]
}</code></pre>

            <p>Vous devez ensuite ex√©cuter la fonction et renvoyer le r√©sultat √† l'API.</p>

            <h2 id="bonnes-pratiques">Bonnes Pratiques</h2>

            <div class="alert alert-info">
                <strong>üí° Conseils :</strong>
                <ul>
                    <li>V√©rifiez toujours <code>finish_reason</code> pour d√©tecter les troncatures</li>
                    <li>Surveillez <code>usage.total_tokens</code> pour contr√¥ler les co√ªts</li>
                    <li>Utilisez le streaming pour une meilleure UX sur les longues r√©ponses</li>
                    <li>G√©rez gracieusement les erreurs avec try/catch</li>
                </ul>
            </div>

            <h2 id="voir-aussi">Voir Aussi</h2>

            <ul>
                <li><a href="./parameters.html">Tous les param√®tres disponibles</a></li>
                <li><a href="./error-codes.html">Guide des codes d'erreur</a></li>
                <li><a href="./optimization.html">Optimiser vos requ√™tes</a></li>
            </ul>

        </main>

        <aside class="docs-toc">
            <h3 class="docs-toc-title">Sur cette page</h3>
            <ul>
                <!-- Generated dynamically by JS -->
            </ul>
        </aside>
    </div>

    <script src="../../assets/js/docs-theme.js"></script>
</body>
</html>
